variables:
  PYTHONPATH: "/meltano/meltano/elt/shared_modules/:$PYTHONPATH"

stages:
  - dev_refresh
  - review
  - build
  - extract
  - model
  - update
  - review_stop

.job_template: &job_definition
  image: registry.gitlab.com/meltano/meltano-elt/extract:latest
  tags:
    - analytics

.job_housekeeping: &job_housekeeping
  image: registry.gitlab.com/meltano/meltano-elt/extract:latest
  tags:
    - housekeeping

.marketo_extract: &marketo_extract
  stage: extract
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - bash processes/mkto_processor.sh
    - stop_cloudsqlproxy

.zendesk_extract: &zendesk_extract
  stage: extract
  allow_failure: true
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - python3 elt/zendesk/src --schema zendesk apply_schema
    - python3 elt/zendesk/src --schema zendesk --days=1 export
    - stop_cloudsqlproxy

.lever_extract: &lever_extract
  stage: extract
  allow_failure: true
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - python3 elt/lever/src --schema lever apply_schema
    - python3 elt/lever/src --schema lever --days=7 export
    - python3 elt/lever/src --schema lever --days=365 --only_offers export
    - stop_cloudsqlproxy

# Stage: extract

## Production Jobs

sfdc_extract:
  variables:
    FIXED_SFDC_PASSWORD: $SFDC_PASSWORD
  stage: extract
  retry: 1
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - envsubst < "elt/config/kettle/kettle.properties" > "$KETTLE_HOME/.kettle/kettle.properties"
    - cp "elt/config/kettle/repositories.xml" "$KETTLE_HOME/.kettle/repositories.xml"
    - kitchen.sh -file=elt/sfdc/sfdc_extract.kjb -level=Minimal
    - stop_cloudsqlproxy

zuora:
  variables:
    FIXED_ZUORA_PASSWORD: $ZUORA_PASSWORD
  stage: extract
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - envsubst < "elt/config/environment.conf.template" > "elt/config/environment.conf"
    - python3 elt/zuora/zuora_export.py
    - stop_cloudsqlproxy

pings_extract:
  stage: extract
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - envsubst < "elt/config/kettle/kettle.properties" > "$KETTLE_HOME/.kettle/kettle.properties"
    - bash elt/util/run_daily_etl.sh
    - stop_cloudsqlproxy

pings:
  stage: extract
  retry: 1
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - bash processes/hosts_to_sfdc/python_timecheck.sh
    - stop_cloudsqlproxy

marketo_extract:
  <<: *marketo_extract
  only:
    - master

zendesk_extract:
  <<: *zendesk_extract
  retry: 1
  only:
    - master

lever_extract:
  <<: *lever_extract
  retry: 1
  only:
    - master

## Review Jobs

marketo_extract_manual:
  <<: *marketo_extract
  only:
    - branches
  except:
    - master
  when: manual

zendesk_extract_manual:
  <<: *zendesk_extract
  retry: 1
  only:
    - branches
  except:
    - master
  when: manual

lever_extract_manual:
  <<: *lever_extract
  retry: 1
  only:
    - branches
  except:
    - master
  when: manual

# Stage: model

dbt:
  stage: model
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - cd elt/dbt
    - dbt -d run --profiles-dir profile --target prod --models sfdc
    - dbt -d run --profiles-dir profile --target version --models pings
    - dbt -d test --profiles-dir profile
    - stop_cloudsqlproxy

sfdc_update:
  stage: update
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - python3 processes/sfdc_processor.py
    - stop_cloudsqlproxy

sfdc_snapshot:
  stage: update
  <<: *job_definition
  script:
    - set_sql_instance_name
    - setup_cloudsqlproxy
    - python3 elt/util/snapshot.py
    - stop_cloudsqlproxy

# Stage: review 

review:
  stage: review
  image: google/cloud-sdk:latest
  variables:
    GIT_STRATEGY: none
  tags:
    - analytics
  script:
    - set_sql_instance_name
    - manage_review_cloudsql
  environment:
    name: review/$CI_COMMIT_REF_NAME
    on_stop: review_stop
  only:
    - branches
  except:
    - master

# Stage: review_stop

review_stop:
  stage: review_stop
  image: google/cloud-sdk:latest
  variables:
    GIT_STRATEGY: none
  script: 
    - set_sql_instance_name
    - delete_review_cloudsql
  when: manual
  allow_failure: true
  only:
    - branches
  except:
    - master
  environment:
    name: review/$CI_COMMIT_REF_NAME
    action: stop

refresh_dev: &refresh_dev
  <<: *job_housekeeping
  stage: dev_refresh
  variables:
    GCP_INSTANCE_NAME: $GCP_PRODUCTION_INSTANCE_NAME
    GIT_STRATEGY: clone # TODO make the script part of the container
  script:
    - refresh_dev_cloudsql
    - setup_cloudsqlproxy $GCP_DEV_INSTANCE_NAME
    - python3 ci_scripts/grant_roles_dev_cloudsql.py
    - stop_cloudsqlproxy
  only:
    - master

force_refresh_dev:
  <<: *refresh_dev
  variables:
    GCP_INSTANCE_NAME: $GCP_PRODUCTION_INSTANCE_NAME
    GIT_STRATEGY: clone # TODO make the script part of the container
    GIT_DEPTH: 1
    FORCE: "true"
  only:
    - branches
    - master
  when: manual


# ---------------------------------------------------------------------------

.meltano: &meltano |

  function auth_gcloud() {
    if [ ${GCP_AUTH:=1} = 0 ]; then
      # already authenticated
      return $GCP_AUTH
    fi

    if [ -n "$GCP_SERVICE_CREDS" ]; then
      echo $GCP_SERVICE_CREDS > gcp_credentials.json
      gcloud auth activate-service-account --key-file=gcp_credentials.json
      export GCP_AUTH=0
    else
      echo "No credentials provided."
      export GCP_AUTH=1
    fi
    
    return $GCP_AUTH
  }

  function set_sql_instance_name() {
    if auth_gcloud; then
      if [ "$CI_COMMIT_REF_NAME" = "master" ]; then
        export GCP_INSTANCE_NAME=$GCP_PRODUCTION_INSTANCE_NAME
      else
        # 95 (max) - 7 (sha) - 2 (`-`) = 86 
        SLUG_LENGTH=$(( 86 - ${#CI_PROJECT_NAME} ))
        export GCP_INSTANCE_REF_SLUG=$CI_PROJECT_NAME-${CI_COMMIT_REF_SLUG:0:$SLUG_LENGTH}
        export GCP_INSTANCE_NAME=$GCP_INSTANCE_REF_SLUG-${CI_COMMIT_SHA:0:7}
      fi
      echo "Instance name is: $GCP_INSTANCE_NAME"
    fi
  }

  function manage_review_cloudsql() {
    # Check to see if branch name equals the production EDW instance name
    if [ "$GCP_INSTANCE_NAME" = "$GCP_PRODUCTION_INSTANCE_NAME" ]; then
      echo "The branch name cannot match the production EDW instance name."
      return 1;
    fi

    if auth_gcloud; then
      # Delete old instances for this branch
      echo "Cleaning up old Cloud SQL instances for this branch."
      gcloud sql instances list --project "$GCP_PROJECT" --filter "$GCP_INSTANCE_REF_SLUG" | tail -n +2 | cut -d' ' -f1 | xargs -I % gcloud sql instances delete --project "$GCP_PROJECT" %

      # Clone new instance and wait for it
      echo "Cloning database..."
      gcloud sql instances clone --project "$GCP_PROJECT" "$GCP_PRODUCTION_INSTANCE_NAME" "$GCP_INSTANCE_NAME" |& grep -E -o '[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}' | head -n1 | xargs -I % gcloud beta sql operations wait --project "$GCP_PROJECT" % || true

    fi
  }

  function delete_review_cloudsql() {
    # Check to see if branch name equals the production EDW instance name
    if [ "$GCP_INSTANCE_NAME" = "$GCP_PRODUCTION_INSTANCE_NAME" ]; then
      echo "The branch name cannot match the production EDW instance name."
      return 1;
    fi

    if auth_gcloud; then
      gcloud sql instances delete --project "$GCP_PROJECT" "$GCP_INSTANCE_NAME"
    fi
  }

  function setup_cloudsqlproxy() {
    INSTANCE_NAME=${1:-$GCP_INSTANCE_NAME}
    if auth_gcloud; then
      cloud_sql_proxy -instances="$GCP_PROJECT:$GCP_REGION:$INSTANCE_NAME"=tcp:5432 -credential_file=gcp_credentials.json -verbose=False &
    fi
  }

  function stop_cloudsqlproxy() {
    kill -9 `pgrep cloud_sql_proxy`
  }

  function refresh_dev_cloudsql() {
    # Get current UTC time
    H=$(date -u +%H)

    # Checks if between 4 and 7 AM UTC (11PM-2AM CST)
    # Prod backups happen between 8-12 AM UTC (3-7 AM CST)
    # 10#$H returns the hour in base 10
    if [ "$FORCE" = "true" ] || (( 4 <= 10#$H && 10#$H < 7 )); then
      if auth_gcloud; then
        echo "Restoring dev instance from latest successful prod backup."
        gcloud config set project "$GCP_PROJECT"
        gcloud sql backups list --instance $GCP_INSTANCE_NAME | grep SUCCESSFUL | head -n 1 | cut -d' ' -f1 | xargs -I % gcloud sql backups restore % --restore-instance=$GCP_DEV_INSTANCE_NAME --backup-instance=$GCP_INSTANCE_NAME
      fi
    else
        echo "Dev instance refresh not run: Only run between the hours of 4 AM UTC and 7 AM UTC"
    fi
  }


before_script:
  - *meltano
